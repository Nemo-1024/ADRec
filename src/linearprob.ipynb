{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.793971Z",
     "start_time": "2025-01-23T13:00:59.792081Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.844061Z",
     "start_time": "2025-01-23T13:00:59.842100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_random_seed_as(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "fix_random_seed_as(2024)"
   ],
   "id": "93b4804f3c834513",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.883587Z",
     "start_time": "2025-01-23T13:00:59.881938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = 'ml-100k'\n",
    "model_name = 'dreamrec'\n",
    "hidden_size=128\n",
    "device='cuda:0'\n",
    "num_class=26\n",
    "batch_size=128"
   ],
   "id": "c72e79cf78d91d6b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.913393Z",
     "start_time": "2025-01-23T13:00:59.911903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pretrained_emb_weight():\n",
    "    path = os.path.join('saved',model_name,dataset_name, 'pretrain.pth')\n",
    "\n",
    "    # path = path_dict[dataset_name]\n",
    "    saved = torch.load(path, map_location='cpu',weights_only=False)\n",
    "    pretrained_emb_weight = saved['item_embedding.weight']\n",
    "    return pretrained_emb_weight"
   ],
   "id": "50887bb572ef9243",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.934350Z",
     "start_time": "2025-01-23T13:00:59.932212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeaturePredictionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeaturePredictionModel, self).__init__()\n",
    "        \n",
    "        # 嵌入层，将 itemID 转换为向量表示\n",
    "        self.embedding = nn.Embedding.from_pretrained(load_pretrained_emb_weight(), padding_idx=0,freeze=True)\n",
    "        self.norm = nn.BatchNorm1d(hidden_size, affine=False)\n",
    "        # MLP 网络\n",
    "        self.Linearproblayer = nn.Linear(hidden_size, num_class)  # 输出是一个标量，假设是回归问题\n",
    "        self.init_weights(self.Linearproblayer)\n",
    "    def init_weights(self,m):\n",
    "        if isinstance(m, nn.Linear):  # 只对线性层初始化\n",
    "            nn.init.xavier_uniform_(m.weight)  # 使用 Xavier 初始化方法\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)  # 将偏置初始化为 0\n",
    "\n",
    "    def forward(self, item_id):\n",
    "        \n",
    "        # 通过嵌入层获取 itemID 的嵌入向量\n",
    "        item_emb = self.embedding(item_id)\n",
    "        item_emb = self.norm(item_emb)\n",
    "        # 通过 MLP 进行预测\n",
    "        x = self.Linearproblayer(item_emb)\n",
    "        return x"
   ],
   "id": "b30890b6ec3c0bc7",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.962896Z",
     "start_time": "2025-01-23T13:00:59.961963Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c5b2108ada15a926",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:00:59.965246Z",
     "start_time": "2025-01-23T13:00:59.963290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = '../datasets/data/' + dataset_name + '/item_class.pkl'\n",
    "df = pd.read_pickle(path)\n",
    "print(df.shape)\n",
    "item_ids = df['item_id'].values\n",
    "features = df.drop(columns=['item_id']).astype(float)  # 去掉 itemID 列\n",
    "# df.head()"
   ],
   "id": "b3ba7d6ba8473986",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 27)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:01:00.004307Z",
     "start_time": "2025-01-23T13:01:00.001944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeaturePredictionDataset(Dataset):\n",
    "    def __init__(self, item_ids, features):\n",
    "        self.item_ids = item_ids\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.item_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_id = self.item_ids[idx]\n",
    "        feature_data = self.features.iloc[idx].values\n",
    "        \n",
    "        # 转换为 torch.Tensor\n",
    "        item_id_tensor = torch.tensor(item_id, dtype=torch.long)  # itemID 用长整型\n",
    "        feature_tensor = torch.tensor(feature_data, dtype=torch.float32)\n",
    "        \n",
    "        return item_id_tensor, feature_tensor\n",
    "\n",
    "# 创建数据集和 DataLoader\n",
    "dataset = FeaturePredictionDataset(item_ids, features)\n",
    "train_data, val_data = torch.utils.data.random_split(dataset,[0.8,0.2], torch.Generator().manual_seed(2024))\n",
    "# print(dataset[0])\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ],
   "id": "41637bd1bafe7e2f",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:01:00.005760Z",
     "start_time": "2025-01-23T13:01:00.004820Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "788e521dc7d88b66",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:01:00.471474Z",
     "start_time": "2025-01-23T13:01:00.032536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型\n",
    "model = FeaturePredictionModel().to(device)# 损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# 训练过程\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_train = 0\n",
    "    correct_train= 0\n",
    "    for item_id, features in train_dataloader:\n",
    "        item_id, features = item_id.to(device), features.to(device)\n",
    "        # 假设 target 是你的目标标签，应该是一个形状为 (batch_size, num_classes) 的 0-1 张量\n",
    "        target = features  # 假设目标是从特征中获取的\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        outputs = model(item_id)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, target)  # BCEWithLogitsLoss 会自动计算 sigmoid 和二分类损失\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 计算训练准确度\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "        predicted_labels = (predictions > 0.5).float()\n",
    "        correct_train += (predicted_labels == target).sum().item()\n",
    "        total_train += target.numel()\n",
    "    # 打印训练信息\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], train Loss: {running_loss/len(train_dataloader):.4f}, train Accuracy: {correct_train/total_train:.4f}\")\n",
    "    # 验证模式\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "    \n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for item_id, features in val_dataloader:\n",
    "            item_id, features = item_id.to(device), features.to(device)\n",
    "\n",
    "            target = features\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(item_id)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            # 计算验证准确度\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            predicted_labels = (predictions > 0.5).float()\n",
    "\n",
    "            # 保存所有预测标签和真实标签\n",
    "            all_val_preds.append(predicted_labels.cpu().numpy())\n",
    "            all_val_targets.append(target.cpu().numpy())\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    # Flatten the list of predictions and targets for classification_report\n",
    "    all_val_preds = np.concatenate(all_val_preds, axis=0)\n",
    "    all_val_targets = np.concatenate(all_val_targets, axis=0)\n",
    "\n",
    "    # 使用 sklearn 的 classification_report 输出详细报告\n",
    "    val_report = classification_report(all_val_targets, all_val_preds, target_names=[f'Class {i}' for i in range(num_class)], zero_division=0)\n",
    "    print(f\"Validation Loss: {running_val_loss / len(val_dataloader):.4f} val Accuracy: {(all_val_preds==all_val_targets).sum()/(all_val_targets.shape[0]*all_val_targets.shape[1]):.4f}\")\n",
    "    if epoch%10==9:\n",
    "        print(f\"Validation Classification Report:\\n{val_report}\")\n",
    "    \n"
   ],
   "id": "f900890cbe2b8c1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], train Loss: 0.8170, train Accuracy: 0.5088\n",
      "Validation Loss: 0.7439 val Accuracy: 0.5245\n",
      "Epoch [2/20], train Loss: 0.6999, train Accuracy: 0.5618\n",
      "Validation Loss: 0.6767 val Accuracy: 0.5819\n",
      "Epoch [3/20], train Loss: 0.6336, train Accuracy: 0.6631\n",
      "Validation Loss: 0.6342 val Accuracy: 0.6933\n",
      "Epoch [4/20], train Loss: 0.5932, train Accuracy: 0.7758\n",
      "Validation Loss: 0.6051 val Accuracy: 0.7782\n",
      "Epoch [5/20], train Loss: 0.5636, train Accuracy: 0.8454\n",
      "Validation Loss: 0.5817 val Accuracy: 0.8224\n",
      "Epoch [6/20], train Loss: 0.5383, train Accuracy: 0.8846\n",
      "Validation Loss: 0.5595 val Accuracy: 0.8490\n",
      "Epoch [7/20], train Loss: 0.5152, train Accuracy: 0.9048\n",
      "Validation Loss: 0.5393 val Accuracy: 0.8617\n",
      "Epoch [8/20], train Loss: 0.4946, train Accuracy: 0.9173\n",
      "Validation Loss: 0.5201 val Accuracy: 0.8739\n",
      "Epoch [9/20], train Loss: 0.4731, train Accuracy: 0.9252\n",
      "Validation Loss: 0.5030 val Accuracy: 0.8816\n",
      "Epoch [10/20], train Loss: 0.4570, train Accuracy: 0.9300\n",
      "Validation Loss: 0.4862 val Accuracy: 0.8907\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.15      0.14      0.14        35\n",
      "     Class 1       0.11      0.15      0.12        13\n",
      "     Class 2       0.00      0.00      0.00         4\n",
      "     Class 3       0.09      0.09      0.09        11\n",
      "     Class 4       0.14      0.10      0.11        21\n",
      "     Class 5       0.08      0.09      0.09        23\n",
      "     Class 6       0.00      0.00      0.00         9\n",
      "     Class 7       0.17      0.13      0.15        54\n",
      "     Class 8       0.00      0.00      0.00         1\n",
      "     Class 9       0.39      0.37      0.38        83\n",
      "    Class 10       0.00      0.00      0.00         0\n",
      "    Class 11       0.00      0.00      0.00         3\n",
      "    Class 12       0.00      0.00      0.00         0\n",
      "    Class 13       0.00      0.00      0.00         0\n",
      "    Class 14       0.25      0.20      0.22        10\n",
      "    Class 15       0.00      0.00      0.00         0\n",
      "    Class 16       0.20      0.30      0.24        10\n",
      "    Class 17       0.00      0.00      0.00         0\n",
      "    Class 18       0.00      0.00      0.00         0\n",
      "    Class 19       0.23      0.23      0.23        39\n",
      "    Class 20       0.00      0.00      0.00         0\n",
      "    Class 21       0.00      0.00      0.00         0\n",
      "    Class 22       0.00      0.00      0.00         0\n",
      "    Class 23       0.27      0.26      0.27        42\n",
      "    Class 24       0.08      0.09      0.08        11\n",
      "    Class 25       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.22      0.20      0.21       373\n",
      "   macro avg       0.08      0.08      0.08       373\n",
      "weighted avg       0.21      0.20      0.21       373\n",
      " samples avg       0.20      0.20      0.18       373\n",
      "\n",
      "Epoch [11/20], train Loss: 0.4403, train Accuracy: 0.9328\n",
      "Validation Loss: 0.4712 val Accuracy: 0.8932\n",
      "Epoch [12/20], train Loss: 0.4240, train Accuracy: 0.9350\n",
      "Validation Loss: 0.4578 val Accuracy: 0.8955\n",
      "Epoch [13/20], train Loss: 0.4101, train Accuracy: 0.9354\n",
      "Validation Loss: 0.4441 val Accuracy: 0.8959\n",
      "Epoch [14/20], train Loss: 0.3967, train Accuracy: 0.9362\n",
      "Validation Loss: 0.4322 val Accuracy: 0.8986\n",
      "Epoch [15/20], train Loss: 0.3830, train Accuracy: 0.9371\n",
      "Validation Loss: 0.4208 val Accuracy: 0.9013\n",
      "Epoch [16/20], train Loss: 0.3723, train Accuracy: 0.9386\n",
      "Validation Loss: 0.4100 val Accuracy: 0.9032\n",
      "Epoch [17/20], train Loss: 0.3604, train Accuracy: 0.9380\n",
      "Validation Loss: 0.4004 val Accuracy: 0.9043\n",
      "Epoch [18/20], train Loss: 0.3513, train Accuracy: 0.9372\n",
      "Validation Loss: 0.3910 val Accuracy: 0.9055\n",
      "Epoch [19/20], train Loss: 0.3426, train Accuracy: 0.9385\n",
      "Validation Loss: 0.3823 val Accuracy: 0.9060\n",
      "Epoch [20/20], train Loss: 0.3309, train Accuracy: 0.9392\n",
      "Validation Loss: 0.3739 val Accuracy: 0.9074\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.20      0.11      0.15        35\n",
      "     Class 1       0.12      0.08      0.10        13\n",
      "     Class 2       0.00      0.00      0.00         4\n",
      "     Class 3       0.00      0.00      0.00        11\n",
      "     Class 4       0.17      0.05      0.07        21\n",
      "     Class 5       0.08      0.04      0.06        23\n",
      "     Class 6       0.00      0.00      0.00         9\n",
      "     Class 7       0.22      0.15      0.18        54\n",
      "     Class 8       0.00      0.00      0.00         1\n",
      "     Class 9       0.40      0.36      0.38        83\n",
      "    Class 10       0.00      0.00      0.00         0\n",
      "    Class 11       0.00      0.00      0.00         3\n",
      "    Class 12       0.00      0.00      0.00         0\n",
      "    Class 13       0.00      0.00      0.00         0\n",
      "    Class 14       0.00      0.00      0.00        10\n",
      "    Class 15       0.00      0.00      0.00         0\n",
      "    Class 16       0.00      0.00      0.00        10\n",
      "    Class 17       0.00      0.00      0.00         0\n",
      "    Class 18       0.00      0.00      0.00         0\n",
      "    Class 19       0.21      0.13      0.16        39\n",
      "    Class 20       0.00      0.00      0.00         0\n",
      "    Class 21       0.00      0.00      0.00         0\n",
      "    Class 22       0.00      0.00      0.00         0\n",
      "    Class 23       0.15      0.07      0.10        42\n",
      "    Class 24       0.00      0.00      0.00        11\n",
      "    Class 25       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.24      0.14      0.18       373\n",
      "   macro avg       0.06      0.04      0.05       373\n",
      "weighted avg       0.20      0.14      0.16       373\n",
      " samples avg       0.19      0.16      0.16       373\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:01:00.473350Z",
     "start_time": "2025-01-23T13:01:00.472334Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4cf5d9d23d9a48b1",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:01:00.474639Z",
     "start_time": "2025-01-23T13:01:00.473711Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "637eaf98db19f6fc",
   "outputs": [],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
